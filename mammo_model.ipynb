{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mammo_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyrusrectus/Capstone-mammogram/blob/main/mammo_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rf4vktLyMsJz"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,\"/content/drive/MyDrive/Capstone/Python files\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL9AMoClO3xb"
      },
      "source": [
        "#This will flip right sided images and crop before resizing to 224 by 224\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import os\n",
        "from skimage import io\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "\n",
        "class MammoTrain(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform =  transforms.Compose([ \n",
        "                 transforms.ToTensor()]) , Flag=True):\n",
        "        self.names = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.Flag = Flag\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "    def __getitem__(self, idx):   \n",
        "        if self.Flag:\n",
        "            img_name = os.path.join(self.root_dir,\n",
        "                                    self.names['Filename'][idx])\n",
        "        else:\n",
        "             img_name = self.names['Filename'][idx]   \n",
        "        image = io.imread(img_name)\n",
        "        if len(image.shape)==3:\n",
        "            image = rgb2gray(image)\n",
        "\n",
        "        if self.names['classification'][idx]==\"Normal\":\n",
        "            label=0\n",
        "        elif self.names['classification'][idx]==\"Benign\":\n",
        "            label=1\n",
        "        else:\n",
        "            label=2\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            image = image.float()\n",
        "            label = torch.tensor(label)\n",
        "        return image,label      \n",
        "\n",
        "    \n",
        "class MammoTest(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform =  transforms.Compose([ \n",
        "                 transforms.ToTensor()]) , Flag=True):\n",
        "        self.names = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.Flag = Flag\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "    def __getitem__(self, idx):   \n",
        "        if self.Flag:\n",
        "            img_name = os.path.join(self.root_dir,\n",
        "                                    self.names['Filename'][idx])\n",
        "        else:\n",
        "             img_name = self.names['Filename'][idx]   \n",
        "        image = io.imread(img_name)\n",
        "        if len(image.shape)==3:\n",
        "            image = rgb2gray(image)\n",
        "        if self.names['classification'][idx]==\"Normal\":\n",
        "            label=0\n",
        "        elif self.names['classification'][idx]==\"Benign\":\n",
        "            label=1\n",
        "        else:\n",
        "            label=2\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            image = image.float()\n",
        "            label = torch.tensor(label)\n",
        "        return image,label  \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9Ze5ROeO_nb"
      },
      "source": [
        "class Config :    \n",
        "    def __init__(self):      \n",
        "        self.gpu       = False\n",
        "        self.gpuid     = 1\n",
        "        self.batchsize = 64\n",
        "        self.epochs    = 50"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKibRKOwdNaI",
        "outputId": "8d051916-a667-43ec-ae62-b3a6e3556f47"
      },
      "source": [
        "import os,time\n",
        "import sklearn.metrics as metrics\n",
        "import scipy.io\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import tqdm\n",
        "import torch.nn as nn\n",
        "from datetime import datetime\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "\n",
        "print ('*******************************************************')\n",
        "start_time=time.time()\n",
        "saveDir='/content/drive/MyDrive/Capstone/savedmodels'\n",
        "cwd=os.getcwd()\n",
        "directory=saveDir+datetime.now().strftime(\"%d%b_%I%M%P_\")+'model'\n",
        "print('Model will be saved to  :', directory)\n",
        "\n",
        "if not os.path.exists(directory):\n",
        "     os.makedirs(directory)\n",
        "\n",
        "config  = Config()\n",
        "\n",
        "weights = np.array([1.38, 4.27, 5.87, 1.00])\n",
        "\n",
        "train_dir=\"/content/drive/MyDrive/Capstone/CSV files/train_mammo.csv\"\n",
        "val_dir=\"/content/drive/MyDrive/Capstone/CSV files/val_mammo.csv\"\n",
        "image_dir=\"/content/drive/MyDrive/Capstone/processed_img\"\n",
        "\n",
        "# make the data iterator for training data\n",
        "train_data = MammoTrain(train_dir,image_dir)\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=config.batchsize, shuffle=True, num_workers=2)\n",
        "\n",
        "val_data = MammoTrain(val_dir,image_dir)\n",
        "valloader = torch.utils.data.DataLoader(val_data, batch_size=config.batchsize, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('----------------------------------------------------------')\n",
        "#%%\n",
        "# Create the object for the network\n",
        "\n",
        "if config.gpu == True:    \n",
        "    net = models.resnet18(pretrained=False)\n",
        "    net.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)    \n",
        "    net.fc=nn.Linear(512,3)\n",
        "    net.cuda()\n",
        "    net.train() \n",
        "    #class_weights = torch.FloatTensor(weights).cuda(config.gpuid)\n",
        "    \n",
        "else:\n",
        "    net = models.resnet18(pretrained=False)\n",
        "    net.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)    \n",
        "    net.fc=nn.Linear(512,3)\n",
        "    \n",
        "\n",
        "   \n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(net.parameters(),lr=5e-4)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Iterate over the training dataset\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "acc = []\n",
        "\n",
        "\n",
        "for j in range(config.epochs):  \n",
        "    # Start epochs   \n",
        "    runtrainloss = 0\n",
        "    runvalloss = 0\n",
        "    \n",
        "    \n",
        "    for i,data in tqdm.tqdm(enumerate(trainloader)): \n",
        "        # start iterations\n",
        "        images,trainLabels = Variable(data[0]),Variable(data[1])\n",
        "        \n",
        "        # ckeck if gpu is available\n",
        "        if config.gpu == True:\n",
        "            images  = images.cuda()\n",
        "            trainLabels = trainLabels.cuda()\n",
        "                    \n",
        "        # make forward pass      \n",
        "        output = net(images)\n",
        "       \n",
        "        #compute loss\n",
        "        loss   = criterion(output, trainLabels)        \n",
        "                \n",
        "        # make gradients zero\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # back propagate\n",
        "        loss.backward()\n",
        "        \n",
        "        # Accumulate loss for current minibatch\n",
        "        runtrainloss += loss.item()\n",
        "        \n",
        "        \n",
        "        # update the parameters\n",
        "        optimizer.step()       \n",
        "        \n",
        "       \n",
        "    # print loss after every epoch\n",
        "    \n",
        "    print('\\n Training - Epoch {}/{}, loss:{:.4f} '.format(j+1, config.epochs, runtrainloss/len(trainloader)))\n",
        "    train_loss.append(runtrainloss/len(trainloader))\n",
        "    \n",
        "       \n",
        "    # Take a step for scheduler\n",
        "    scheduler.step()\n",
        "    \n",
        "    net.eval()\n",
        "    total =0\n",
        "    correct = 0\n",
        "    for i,data in tqdm.tqdm(enumerate(valloader)): \n",
        "         # start iterations\n",
        "         images,valLabels = Variable(data[0]),Variable(data[1])\n",
        "        \n",
        "    #     # ckeck if gpu is available\n",
        "         if config.gpu == True:\n",
        "             images  = images.cuda()\n",
        "             valLabels = valLabels.cuda()\n",
        "                    \n",
        "    #     # make forward pass      \n",
        "         output = net(images)\n",
        "        \n",
        "    #     # Find Accuracy\n",
        "         _, predicted = torch.max(F.softmax(output, dim=1), dim=1)\n",
        "         total += valLabels.size(0)\n",
        "         correct += (predicted == valLabels).sum().item()\n",
        "       \n",
        "    #     #compute loss\n",
        "         loss   = criterion(output, valLabels)        \n",
        "                \n",
        "    #     # Accumulate loss for current minibatch\n",
        "         runvalloss += loss.item()\n",
        "        \n",
        "           \n",
        "    # # print loss after every epoch\n",
        "    \n",
        "    print(' \\n Validatn - Epoch {}/{}, loss:{:.4f}, Acc:{:.4f}'.format(j+1, \n",
        "                 config.epochs, runvalloss/len(valloader), correct / total))\n",
        "    val_loss.append(runvalloss/len(valloader))\n",
        "    acc.append(correct / total)\n",
        "    \n",
        "    print('----------------------------------------------------------')\n",
        "    \n",
        "    \n",
        "    #save the model   \n",
        "    torch.save(net.state_dict(),os.path.join(directory,\"Resnet_crop_flip\" + str(j+1) +\"_model.pth\"))\n",
        "    \n",
        "    \n",
        "    \t    \n",
        "\n",
        "# Save the train stats\n",
        "\n",
        "np.save(directory + '/trnloss.npy',np.array(train_loss) )\n",
        "np.save(directory + '/valloss.npy',np.array(val_loss) )\n",
        "np.save(directory + '/acc.npy',    np.array(   acc    ) )\n",
        "\n",
        "\n",
        "# plot the training loss\n",
        "\n",
        "x = range(config.epochs)\n",
        "plt.figure()\n",
        "plt.plot(x,train_loss,label='Training')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Train Loss ') \n",
        "plt.legend(loc=\"upper left\")  \n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(x,val_loss,label='Validation')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Val Loss ') \n",
        "plt.legend(loc=\"upper left\")  \n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(x,acc,label='Validation')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Val acc ') \n",
        "plt.legend(loc=\"upper left\")  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*******************************************************\n",
            "Model will be saved to  : /content/drive/MyDrive/Capstone/savedmodels15Jul_0541pm_model\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "53it [11:33, 13.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Training - Epoch 1/50, loss:1.0211 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "13it [01:45,  8.12s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " \n",
            " Validatn - Epoch 1/50, loss:0.9418, Acc:0.5613\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "34it [07:03, 12.48s/it]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}